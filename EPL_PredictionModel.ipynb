{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b1a5b9a-6125-4c9c-a2fb-8159753c5d25",
   "metadata": {},
   "source": [
    "## STEP 1 : Updating the matchdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46583742-94ba-45ea-95ad-40576f95cfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "standings_url = \"https://fbref.com/en/comps/9/schedule/Premier-League-Scores-and-Fixtures\"\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "response = requests.get(standings_url, headers=headers)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    raise Exception(f\"Failed to load page {standings_url}. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45062cf7-4f73-476f-a19e-2484b52b1aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the standings table\n",
    "standings_table = soup.select_one('table.stats_table')\n",
    "if not standings_table:\n",
    "    raise Exception(\"Standings table not found.\")\n",
    "\n",
    "headers = [th.get_text(strip=True) for th in standings_table.find('thead').find_all('th')]\n",
    "\n",
    "# Extract rows and align with headers\n",
    "rows = standings_table.find('tbody').find_all('tr')\n",
    "data = []\n",
    "\n",
    "for row in rows:\n",
    "    columns = row.find_all(['th', 'td'])  # Include <th> for row headers\n",
    "    row_data = [col.get_text(strip=True) for col in columns]\n",
    "    \n",
    "    # Check if the number of columns matches the headers\n",
    "    if len(row_data) == len(headers):\n",
    "        data.append(dict(zip(headers, row_data)))\n",
    "    else:\n",
    "        # Handle cases where some columns are missing or extra\n",
    "        print(f\"Row with mismatched columns skipped: {row_data}\")\n",
    "\n",
    "matchday_collection = pd.DataFrame(data)\n",
    "\n",
    "# matchday_collection.count()\n",
    "matchday_collection.to_csv(\"matchday_collection.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d83fb96-cfe6-42ae-963d-96ed9fe8c1ff",
   "metadata": {},
   "source": [
    "## Finding Relevent latest upcoming matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7710bf5-3411-40ab-936d-b425e7d204fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ab\\AppData\\Local\\Temp\\ipykernel_10616\\3068223063.py:12: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  matchday_collection['date'] = pd.to_datetime(matchday_collection['date'], dayfirst=True, errors='coerce')\n",
      "C:\\Users\\ab\\AppData\\Local\\Temp\\ipykernel_10616\\3068223063.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nxt_week_matches['home'] = nxt_week_matches['home'].replace(team_name_mapping)\n",
      "C:\\Users\\ab\\AppData\\Local\\Temp\\ipykernel_10616\\3068223063.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  nxt_week_matches['away'] = nxt_week_matches['away'].replace(team_name_mapping)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "file_path = \"matchday_collection.csv\"\n",
    "matchday_collection = pd.read_csv(file_path)\n",
    "\n",
    "# Standardize column names\n",
    "matchday_collection.columns = matchday_collection.columns.str.lower().str.strip()\n",
    "\n",
    "# Ensure 'date' is in datetime format\n",
    "if 'date' in matchday_collection.columns:\n",
    "    matchday_collection['date'] = pd.to_datetime(matchday_collection['date'], dayfirst=True, errors='coerce')\n",
    "\n",
    "    # Drop rows where 'date' could not be parsed (invalid dates)\n",
    "    matchday_collection = matchday_collection.dropna(subset=['date'])\n",
    "\n",
    "# Filter for upcoming matches where 'match report' is \"Head-to-Head\"\n",
    "upcoming_matches = matchday_collection[matchday_collection['match report'] == \"Head-to-Head\"]\n",
    "\n",
    "# Find the minimum week (Wk) value\n",
    "if 'wk' in upcoming_matches.columns:\n",
    "    min_week = upcoming_matches['wk'].min()\n",
    "    nxt_week_matches = upcoming_matches[upcoming_matches['wk'].isin((min_week, min_week+1)) ]\n",
    "\n",
    "# Mapping of team abbreviations to full names\n",
    "team_name_mapping = {\n",
    "    \"Manchester Utd\": \"Manchester United\",\n",
    "    \"Manchester City\": \"Manchester City\",\n",
    "    \"Tottenham\": \"Tottenham Hotspur\",\n",
    "    \"Nott'ham Forest\": \"Nottingham Forest\",\n",
    "    \"Ipswich Town\": \"Ipswich Town\",\n",
    "    \"Wolves\": \"Wolverhampton Wanderers\",\n",
    "    \"West Ham\": \"West Ham United\",\n",
    "    \"Brighton\": \"Brighton and Hove Albion\",\n",
    "    \"Arsenal\": \"Arsenal\",\n",
    "    \"Liverpool\": \"Liverpool\",\n",
    "    \"Chelsea\": \"Chelsea\",\n",
    "    \"Newcastle Utd\": \"Newcastle United\",\n",
    "    \"Bournemouth\": \"Bournemouth\",\n",
    "    \"Southampton\": \"Southampton\",\n",
    "    \"Crystal Palace\": \"Crystal Palace\",\n",
    "    \"Leicester City\": \"Leicester City\",\n",
    "    \"Aston Villa\": \"Aston Villa\",\n",
    "    \"Everton\": \"Everton\",\n",
    "    \"Fulham\": \"Fulham\",\n",
    "    \"Brentford\": \"Brentford\"\n",
    "}\n",
    "\n",
    "\n",
    "# Update team names in 'home' and 'away' columns\n",
    "nxt_week_matches['home'] = nxt_week_matches['home'].replace(team_name_mapping)\n",
    "nxt_week_matches['away'] = nxt_week_matches['away'].replace(team_name_mapping)\n",
    "\n",
    "#nxt_week_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e36b818b-ef8e-46e5-999e-dc0db514046e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi\n",
    "\n",
    "uri = \"mongodb+srv://abhi_mongobd_user:abhi_mongobd_user@freecluster0.i05lv.mongodb.net/?retryWrites=true&w=majority&appName=FreeCluster0\"\n",
    "\n",
    "# Create a new client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1132c73a-69a2-4a6b-8626-dab866bf7bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Results for Next Week Matches:\n",
      "      wk                home_team                 away_team  home_goals  \\\n",
      "0   20.0                   Fulham              Ipswich Town           1   \n",
      "1   20.0                Liverpool         Manchester United           3   \n",
      "2   20.0  Wolverhampton Wanderers         Nottingham Forest           2   \n",
      "3   21.0                Brentford           Manchester City           1   \n",
      "4   21.0          West Ham United                    Fulham           1   \n",
      "5   21.0                  Chelsea               Bournemouth           2   \n",
      "6   21.0        Nottingham Forest                 Liverpool           1   \n",
      "7   21.0                  Everton               Aston Villa           1   \n",
      "8   21.0         Newcastle United   Wolverhampton Wanderers           3   \n",
      "9   21.0           Leicester City            Crystal Palace           1   \n",
      "10  21.0                  Arsenal         Tottenham Hotspur           3   \n",
      "11  21.0             Ipswich Town  Brighton and Hove Albion           0   \n",
      "12  21.0        Manchester United               Southampton           0   \n",
      "\n",
      "    away_goals  \n",
      "0            3  \n",
      "1            2  \n",
      "2            0  \n",
      "3            1  \n",
      "4            1  \n",
      "5            0  \n",
      "6            2  \n",
      "7            2  \n",
      "8            1  \n",
      "9            1  \n",
      "10           2  \n",
      "11           2  \n",
      "12           1  \n",
      "Saved 13 records to predictions in epl_2024_25 database.\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "\n",
    "db_name=\"abhi_mongobd_user\"\n",
    "collection_name=\"epl2024_25.epl_predictions\"\n",
    "mongo_uri = \"mongodb+srv://abhi_mongobd_user:abhi_mongobd_user@freecluster0.i05lv.mongodb.net/?retryWrites=true&w=majority&appName=FreeCluster0\"\n",
    "\n",
    "def save_to_mongodb(predictions_df, db_name, collection_name, mongo_uri):\n",
    "    \"\"\"\n",
    "    Save the predictions DataFrame to a MongoDB collection.\n",
    "    \n",
    "    Args:\n",
    "        predictions_df (pd.DataFrame): The DataFrame containing predictions.\n",
    "        db_name (str): The name of the database.\n",
    "        collection_name (str): The name of the collection.\n",
    "        mongo_uri (str): The MongoDB connection URI.\n",
    "    \"\"\"\n",
    "    # Connect to MongoDB\n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "    \n",
    "    # Convert DataFrame to dictionary and insert into MongoDB\n",
    "    data = predictions_df.to_dict(orient=\"records\")\n",
    "    collection.insert_many(data)\n",
    "    \n",
    "    print(f\"Saved {len(data)} records to {collection_name} in {db_name} database.\")\n",
    "\n",
    "# Predict scorelines for upcoming matches\n",
    "def predict_upcoming_matches(nxt_week_matches, home_model, away_model, scaler, matches_preprocessed):\n",
    "    predictions = []\n",
    "    \n",
    "    for _, row in nxt_week_matches.iterrows():\n",
    "        home_team = row['home']\n",
    "        away_team = row['away']\n",
    "        wk = row['wk']\n",
    "        \n",
    "        # Get stats for both teams from preprocessed data\n",
    "        try:\n",
    "            home_stats = matches_preprocessed[matches_preprocessed['team'] == home_team].iloc[-1]\n",
    "            away_stats = matches_preprocessed[matches_preprocessed['team'] == away_team].iloc[-1]\n",
    "            \n",
    "            # Create feature vectors\n",
    "            home_features = np.array([\n",
    "                home_stats['recent_gf'], home_stats['recent_ga'],\n",
    "                home_stats['recent_xg'], home_stats['recent_xga'],\n",
    "                home_stats['recent_poss'], home_stats['recent_sh'],\n",
    "                home_stats['recent_sot'], home_stats['avg_gf'],\n",
    "                home_stats['avg_ga'], home_stats['avg_xg'],\n",
    "                home_stats['avg_xga'], 1  # Home team indicator\n",
    "            ]).reshape(1, -1)\n",
    "            \n",
    "            away_features = np.array([\n",
    "                away_stats['recent_gf'], away_stats['recent_ga'],\n",
    "                away_stats['recent_xg'], away_stats['recent_xga'],\n",
    "                away_stats['recent_poss'], away_stats['recent_sh'],\n",
    "                away_stats['recent_sot'], away_stats['avg_gf'],\n",
    "                away_stats['avg_ga'], away_stats['avg_xg'],\n",
    "                away_stats['avg_xga'], 0  # Away team indicator\n",
    "            ]).reshape(1, -1)\n",
    "            \n",
    "            # Scale features and predict scores\n",
    "            home_features_scaled = scaler.transform(home_features)\n",
    "            away_features_scaled = scaler.transform(away_features)\n",
    "            \n",
    "            predicted_home_goals = round(home_model.predict(home_features_scaled)[0])\n",
    "            predicted_away_goals = round(away_model.predict(away_features_scaled)[0])\n",
    "            \n",
    "            predictions.append({\n",
    "                \"wk\": wk,\n",
    "                \"home_team\": home_team,\n",
    "                \"away_team\": away_team,\n",
    "                \"home_goals\": predicted_home_goals,\n",
    "                \"away_goals\": predicted_away_goals\n",
    "            })\n",
    "        \n",
    "        except IndexError:\n",
    "            print(f\"Insufficient data for {home_team} vs {away_team}\")\n",
    "    \n",
    "    return pd.DataFrame(predictions)\n",
    "\n",
    "# Train models using historical data\n",
    "def train_models(matches_preprocessed):\n",
    "    features = [\n",
    "        'recent_gf', 'recent_ga', 'recent_xg', 'recent_xga',\n",
    "        'recent_poss', 'recent_sh', 'recent_sot',\n",
    "        'avg_gf', 'avg_ga', 'avg_xg', 'avg_xga',\n",
    "        'is_home'\n",
    "    ]\n",
    "    \n",
    "    X = matches_preprocessed[features]\n",
    "    y_home_goals = matches_preprocessed['gf']\n",
    "    y_away_goals = matches_preprocessed['ga']\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Train home and away goal models\n",
    "    home_model = RandomForestRegressor(\n",
    "        n_estimators=500,\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    away_model = RandomForestRegressor(\n",
    "        n_estimators=500,\n",
    "        max_depth=10,\n",
    "        min_samples_split=5,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    home_model.fit(X_scaled, y_home_goals)\n",
    "    away_model.fit(X_scaled, y_away_goals)\n",
    "    \n",
    "    return home_model, away_model, scaler\n",
    "\n",
    "# Preprocess historical match data\n",
    "def preprocess_data(matches):\n",
    "    matches['date'] = pd.to_datetime(matches['date'], dayfirst=True)\n",
    "    matches = matches.sort_values(by=['team', 'date'])\n",
    "    \n",
    "    # Add form features (last 5 matches)\n",
    "    form_features = ['gf', 'ga', 'xg', 'xga', 'poss', 'sh', 'sot']\n",
    "    for feature in form_features:\n",
    "        # Recent form (last 5 matches)\n",
    "        matches[f'recent_{feature}'] = matches.groupby('team')[feature].transform(\n",
    "            lambda x: x.rolling(5, min_periods=1).mean()\n",
    "        )\n",
    "        # Overall average\n",
    "        matches[f'avg_{feature}'] = matches.groupby('team')[feature].transform('mean')\n",
    "    \n",
    "    # Add home/away indicator\n",
    "    matches['is_home'] = (matches['venue'] == 'Home').astype(int)\n",
    "    \n",
    "    return matches    \n",
    "\n",
    "def main():\n",
    "    # Load historical match data and upcoming match data\n",
    "    historical_matches_path = \"df_union.csv\"\n",
    "        \n",
    "    historical_matches = pd.read_csv(historical_matches_path)\n",
    "        \n",
    "    # Preprocess historical data\n",
    "    historical_matches_preprocessed = preprocess_data(historical_matches)\n",
    "    \n",
    "    # Train models using historical data\n",
    "    home_model, away_model, scaler = train_models(historical_matches_preprocessed)\n",
    "    \n",
    "    # Generate predictions for next week's matches\n",
    "    predictions_df = predict_upcoming_matches(\n",
    "        nxt_week_matches=nxt_week_matches,\n",
    "        home_model=home_model,\n",
    "        away_model=away_model,\n",
    "        scaler=scaler,\n",
    "        matches_preprocessed=historical_matches_preprocessed\n",
    "    )\n",
    "    \n",
    "    print(\"\\nPredicted Results for Next Week Matches:\")\n",
    "    print(predictions_df)\n",
    "    \n",
    "    # Save predictions to MongoDB\n",
    "    mongo_uri = \"mongodb+srv://abhi_mongobd_user:abhi_mongobd_user@freecluster0.i05lv.mongodb.net/?retryWrites=true&w=majority&appName=FreeCluster0\"\n",
    "    save_to_mongodb(predictions_df, db_name=\"epl_2024_25\", collection_name=\"predictions\", mongo_uri=mongo_uri)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
